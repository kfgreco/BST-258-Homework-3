prob_A <- exp(0.25 * L1 + 0.5 * L3 - 0.3 * L5) / (1 + exp(0.25 * L1 + 0.5 * L3 - 0.3 * L5))
A <- rbinom(n, 1, prob_A)
Y <- 2 * A + L1 - L2 * 0.5 + L3 + L4 * 0.1 + rnorm(n)
return(data.frame(L1, L2, L3, L4, L5, L6, L7, L8, L9, L10, A, Y))
}
library(dplyr)
# Function to calculate expected conditional covariance
calculate_Psi_P <- function(data) {
# Calculate E(A | L) for each observation
data <- data %>%
mutate(E_A_L = plogis(0.25 * L1 + 0.5 * L3 - 0.3 * L5),
Var_A_L = E_A_L * (1 - E_A_L), # Variance of A given L
Cov_YA_L = 2 * Var_A_L) # 2 times variance because Y = 2A + other terms
# Calculate expected conditional covariance
Psi_P <- mean(data$Cov_YA_L)
return(Psi_P)
}
# Generate a large dataset for a good approximation
data <- simulate_data(100000)
# Calculate Psi(P)
Psi_P_estimate <- calculate_Psi_P(data)
Psi_P_estimate
rm(list = ls())
library(ggplot2)
library(mgcv)
library(dplyr)
library(tidyr)
library(dplyr)
library(broom)
library(boot)
# Generate data
simulate_data <- function(n) {
L1 <- rnorm(n)
L2 <- runif(n, 0, 1)
L3 <- rbinom(n, 1, 0.5)
L4 <- rpois(n, 2)
L5 <- rexp(n, 1)
L6 <- rnorm(n, mean = L1 * 0.5)
L7 <- rbinom(n, 1, L2)
L8 <- ifelse(L3 == 1, rnorm(n, 1), rnorm(n, -1))
L9 <- rlogis(n)
L10 <- abs(rnorm(n)) + L4 * 0.1
prob_A <- exp(0.25 * L1 + 0.5 * L3 - 0.3 * L5) / (1 + exp(0.25 * L1 + 0.5 * L3 - 0.3 * L5))
A <- rbinom(n, 1, prob_A)
Y <- 2 * A + L1 - L2 * 0.5 + L3 + L4 * 0.1 + rnorm(n)
return(data.frame(L1, L2, L3, L4, L5, L6, L7, L8, L9, L10, A, Y))
}
data <- simulate_data(100000)
data <- simulate_data(100000)
# Compute true value of parameter
calculate_Psi_P <- function(data) {
# Calculate E(A|L) for each observation
data <- data %>%
mutate(E_A_L = plogis(0.25 * L1 + 0.5 * L3 - 0.3 * L5),
Var_A_L = E_A_L * (1 - E_A_L),
Cov_YA_L = 2 * Var_A_L)
# Calculate expected conditional covariance
Psi_P <- mean(data$Cov_YA_L)
return(Psi_P)
}
# Calculate Psi(P)
Psi_P_estimate <- calculate_Psi_P(data)
Psi_P_estimate
data <- simulate_data(100000)
# Compute true value of parameter
Psi_P <- function(data) {
# Calculate E(A|L) for each observation
data <- data %>%
mutate(E_A_L = plogis(0.25 * L1 + 0.5 * L3 - 0.3 * L5),
Var_A_L = E_A_L * (1 - E_A_L),
Cov_YA_L = 2 * Var_A_L)
# Calculate expected conditional covariance
Psi_P <- mean(data$Cov_YA_L)
return(Psi_P)
}
# Calculate Psi(P)
Psi_P_true <- Psi_P(data)
library(tidyverse)
# Simulate L
simulate_L <- function(n) {
tibble(
L1 = rnorm(n),
L3 = rbinom(n, 1, 0.5),
L5 = rexp(n, 1)
)
}
# Calculate E(A | L)
E_A_given_L <- function(L) {
plogis(0.25 * L$L1 + 0.5 * L$L3 - 0.3 * L$L5)
}
# Calculate expected conditional covariance
Psi_P <- function(n) {
L <- simulate_L(n)
E_A_L <- E_A_given_L(L)
mean(2 * E_A_L * (1 - E_A_L))
}
# Estimate Psi(P) with a large sample
Psi_P_estimate <- Psi_P(100000)
Psi_P_estimate
data <- simulate_data(1000000)
# Compute true value of parameter
Psi_P <- function(data) {
# Calculate E(A|L) for each observation
data <- data %>%
mutate(E_A_L = plogis(0.25 * L1 + 0.5 * L3 - 0.3 * L5),
Var_A_L = E_A_L * (1 - E_A_L),
Cov_YA_L = 2 * Var_A_L)
# Calculate expected conditional covariance
Psi_P <- mean(data$Cov_YA_L)
return(Psi_P)
}
# Calculate Psi(P)
Psi_P_true <- Psi_P(data)
Psi_P_true
# rm(list = ls())
set.seed(2024)
library(ggplot2)
library(mgcv)
library(dplyr)
library(tidyr)
library(dplyr)
library(broom)
library(boot)
# Generate data
simulate_data <- function(n) {
L1 <- rnorm(n)
L2 <- runif(n, 0, 1)
L3 <- rbinom(n, 1, 0.5)
L4 <- rpois(n, 2)
L5 <- rexp(n, 1)
L6 <- rnorm(n, mean = L1 * 0.5)
L7 <- rbinom(n, 1, L2)
L8 <- ifelse(L3 == 1, rnorm(n, 1), rnorm(n, -1))
L9 <- rlogis(n)
L10 <- abs(rnorm(n)) + L4 * 0.1
prob_A <- exp(0.25 * L1 + 0.5 * L3 - 0.3 * L5) / (1 + exp(0.25 * L1 + 0.5 * L3 - 0.3 * L5))
A <- rbinom(n, 1, prob_A)
Y <- 2 * A + L1 - L2 * 0.5 + L3 + L4 * 0.1 + rnorm(n)
return(data.frame(L1, L2, L3, L4, L5, L6, L7, L8, L9, L10, A, Y))
}
data <- simulate_data(1000000)
# Compute true value of parameter
Psi_P <- function(data) {
# Calculate E(A|L) for each observation
data <- data %>%
mutate(E_A_L = plogis(0.25 * L1 + 0.5 * L3 - 0.3 * L5),
Var_A_L = E_A_L * (1 - E_A_L),
Cov_YA_L = 2 * Var_A_L)
# Calculate expected conditional covariance
Psi_P <- mean(data$Cov_YA_L)
return(Psi_P)
}
# Calculate Psi(P)
Psi_P_true <- Psi_P(data)
# Function to calculate one-step estimator
one_step_estimator <- function(data) {
fit_Y <- glm(Y ~ L1 + L2 + L3 + L4 + L5 + L6 + L7 + L8 + L9 + L10, data=data, family=gaussian())
fit_A <- glm(A ~ L1 + L2 + L3 + L4 + L5 + L6 + L7 + L8 + L9 + L10, data=data, family=gaussian())
m_hat <- predict(fit_Y, newdata=data, type="response")
pi_hat <- predict(fit_A, newdata=data, type="response")
psi_hat_OS <- mean((data$Y - m_hat) * (data$A - pi_hat))
return(psi_hat_OS)
}
# Set simulation parameters
n_sizes <- c(100, 400, 900, 1600, 2500)
n_simulations <- 100
# Store results here
results <- data.frame(sample_size=rep(n_sizes, each=n_simulations), estimate=NA)
# Perform simulations
for (i in 1:nrow(results)) {
data <- simulate_data(results$sample_size[i])
results$estimate[i] <- one_step_estimator(data)
}
# Visualize the sampling distributions
ggplot(results, aes(x=estimate, fill=factor(sample_size))) +
geom_density(alpha=0.6) +
theme_minimal() +
labs(title="Sampling Distribution of the One-Step Estimator using GLM",
x="Estimate", y="Density", fill="Sample Size")
# Report summary statistics for each sample size
summary_stats_glm <- results %>%
group_by(sample_size) %>%
summarise(
mean_estimate = mean(estimate),
sd = sd(estimate),
var = var(estimate),
bias = mean_estimate - Psi_P_true
)
print(summary_stats_glm)
Psi_P_true
# rm(list = ls())
set.seed(2024)
library(ggplot2)
library(mgcv)
library(dplyr)
library(tidyr)
library(dplyr)
library(broom)
library(boot)
# Generate data
simulate_data <- function(n) {
L1 <- rnorm(n)
L2 <- runif(n, 0, 1)
L3 <- rbinom(n, 1, 0.5)
L4 <- rpois(n, 2)
L5 <- rexp(n, 1)
L6 <- rnorm(n, mean = L1 * 0.5)
L7 <- rbinom(n, 1, L2)
L8 <- ifelse(L3 == 1, rnorm(n, 1), rnorm(n, -1))
L9 <- rlogis(n)
L10 <- abs(rnorm(n)) + L4 * 0.1
prob_A <- exp(0.25 * L1 + 0.5 * L3 - 0.3 * L5) / (1 + exp(0.25 * L1 + 0.5 * L3 - 0.3 * L5))
A <- rbinom(n, 1, prob_A)
Y <- 2 * A + L1 - L2 * 0.5 + L3 + L4 * 0.1 + rnorm(n)
return(data.frame(L1, L2, L3, L4, L5, L6, L7, L8, L9, L10, A, Y))
}
data <- simulate_data(1000000)
# Compute true value of parameter
Psi_P <- function(data) {
# Calculate E(A|L) for each observation
data <- data %>%
mutate(E_A_L = plogis(0.25 * L1 + 0.5 * L3 - 0.3 * L5),
Var_A_L = E_A_L * (1 - E_A_L),
Cov_YA_L = 2 * Var_A_L)
# Calculate expected conditional covariance
Psi_P <- mean(data$Cov_YA_L)
return(Psi_P)
}
# Calculate Psi(P)
Psi_P_true <- Psi_P(data)
# Function to calculate one-step estimator
one_step_estimator <- function(data) {
fit_Y <- glm(Y ~ L1 + L2 + L3 + L4 + L5 + L6 + L7 + L8 + L9 + L10, data=data, family=gaussian())
fit_A <- glm(A ~ L1 + L2 + L3 + L4 + L5 + L6 + L7 + L8 + L9 + L10, data=data, family=gaussian())
m_hat <- predict(fit_Y, newdata=data, type="response")
pi_hat <- predict(fit_A, newdata=data, type="response")
psi_hat_OS <- mean((data$Y - m_hat) * (data$A - pi_hat))
return(psi_hat_OS)
}
# Set simulation parameters
n_sizes <- c(100, 400, 900, 1600, 2500)
n_simulations <- 100
# Store results here
results <- data.frame(sample_size=rep(n_sizes, each=n_simulations), estimate=NA)
# Perform simulations
for (i in 1:nrow(results)) {
data <- simulate_data(results$sample_size[i])
results$estimate[i] <- one_step_estimator(data)
}
# Visualize the sampling distributions
ggplot(results, aes(x=estimate, fill=factor(sample_size))) +
geom_density(alpha=0.6) +
geom_vline(xintercept = Psi_P_true, color = "black", linetype = "dashed", size = 1,
show.legend = TRUE, label = "Psi_P_true") +
theme_minimal() +
labs(title="Sampling Distribution of the One-Step Estimator using GLM",
x="Estimate", y="Density", fill="Sample Size")
# Report summary statistics for each sample size
summary_stats_glm <- results %>%
group_by(sample_size) %>%
summarise(
mean_estimate = mean(estimate),
sd = sd(estimate),
var = var(estimate),
bias = mean_estimate - Psi_P_true
)
print(summary_stats_glm)
#| echo: false
#| message: false
#| label: global-setup
library(here)
# rm(list = ls())
set.seed(2024)
library(ggplot2)
library(mgcv)
library(dplyr)
library(tidyr)
library(dplyr)
library(broom)
library(boot)
# Generate data
simulate_data <- function(n) {
L1 <- rnorm(n)
L2 <- runif(n, 0, 1)
L3 <- rbinom(n, 1, 0.5)
L4 <- rpois(n, 2)
L5 <- rexp(n, 1)
L6 <- rnorm(n, mean = L1 * 0.5)
L7 <- rbinom(n, 1, L2)
L8 <- ifelse(L3 == 1, rnorm(n, 1), rnorm(n, -1))
L9 <- rlogis(n)
L10 <- abs(rnorm(n)) + L4 * 0.1
prob_A <- exp(0.25 * L1 + 0.5 * L3 - 0.3 * L5) / (1 + exp(0.25 * L1 + 0.5 * L3 - 0.3 * L5))
A <- rbinom(n, 1, prob_A)
Y <- 2 * A + L1 - L2 * 0.5 + L3 + L4 * 0.1 + rnorm(n)
return(data.frame(L1, L2, L3, L4, L5, L6, L7, L8, L9, L10, A, Y))
}
data <- simulate_data(1000000)
# Compute true value of parameter
Psi_P <- function(data) {
# Calculate E(A|L) for each observation
data <- data %>%
mutate(E_A_L = plogis(0.25 * L1 + 0.5 * L3 - 0.3 * L5),
Var_A_L = E_A_L * (1 - E_A_L),
Cov_YA_L = 2 * Var_A_L)
# Calculate expected conditional covariance
Psi_P <- mean(data$Cov_YA_L)
return(Psi_P)
}
# Calculate Psi(P)
Psi_P_true <- Psi_P(data)
# Function to calculate one-step estimator
one_step_estimator <- function(data) {
fit_Y <- glm(Y ~ L1 + L2 + L3 + L4 + L5 + L6 + L7 + L8 + L9 + L10, data=data, family=gaussian())
fit_A <- glm(A ~ L1 + L2 + L3 + L4 + L5 + L6 + L7 + L8 + L9 + L10, data=data, family=gaussian())
m_hat <- predict(fit_Y, newdata=data, type="response")
pi_hat <- predict(fit_A, newdata=data, type="response")
psi_hat_OS <- mean((data$Y - m_hat) * (data$A - pi_hat))
return(psi_hat_OS)
}
# Set simulation parameters
n_sizes <- c(100, 400, 900, 1600, 2500)
n_simulations <- 100
# Store results here
results <- data.frame(sample_size=rep(n_sizes, each=n_simulations), estimate=NA)
# Perform simulations
for (i in 1:nrow(results)) {
data <- simulate_data(results$sample_size[i])
results$estimate[i] <- one_step_estimator(data)
}
# Visualize the sampling distributions
ggplot(results, aes(x=estimate, fill=factor(sample_size))) +
geom_density(alpha=0.6) +
geom_vline(xintercept = Psi_P_true, color = "black", linetype = "dashed", size = 1,
show.legend = TRUE, label = "Psi_P_true") +
theme_minimal() +
labs(title="Sampling Distribution of the One-Step Estimator using GLM",
x="Estimate", y="Density", fill="Sample Size")
# Report summary statistics for each sample size
summary_stats_glm <- results %>%
group_by(sample_size) %>%
summarise(
mean_estimate = mean(estimate),
sd = sd(estimate),
var = var(estimate),
bias = mean_estimate - Psi_P_true
)
print(summary_stats_glm)
set.seed(2024)
# Modified function to calculate one-step estimator using GAM
one_step_estimator_gam <- function(data) {
fit_Y <- gam(Y ~ s(L1) + s(L2) +  s(L5) + s(L6) + s(L8) + s(L9) + s(L10), data=data)
fit_A <- gam(A ~ s(L1) + s(L2) +  s(L5) + s(L6) + s(L8) + s(L9) + s(L10), data=data, family=binomial)
m_hat <- predict(fit_Y, newdata=data, type="response")
pi_hat <- predict(fit_A, newdata=data, type="response")
psi_hat_OS <- mean((data$Y - m_hat) * (data$A - pi_hat))
return(psi_hat_OS)
}
# Set simulation parameters
n_sizes <- c(100)
n_simulations <- 5
# n_sizes <- c(100, 400, 900, 1600, 2500)
# n_simulations <- 100
results <- data.frame(sample_size=rep(n_sizes, each=n_simulations), estimate=NA)
results
set.seed(2024)
# Modified function to calculate one-step estimator using GAM
one_step_estimator_gam <- function(data) {
fit_Y <- gam(Y ~ s(L1) + s(L2) +  s(L5) + s(L6) + s(L8) + s(L9) + s(L10), data=data)
fit_A <- gam(A ~ s(L1) + s(L2) +  s(L5) + s(L6) + s(L8) + s(L9) + s(L10), data=data, family=binomial)
m_hat <- predict(fit_Y, newdata=data, type="response")
pi_hat <- predict(fit_A, newdata=data, type="response")
psi_hat_OS <- mean((data$Y - m_hat) * (data$A - pi_hat))
return(psi_hat_OS)
}
# Set simulation parameters
n_sizes <- c(100)
n_simulations <- 5
# n_sizes <- c(100, 400, 900, 1600, 2500)
# n_simulations <- 100
results <- data.frame(sample_size=rep(n_sizes, each=n_simulations), estimate=NA)
for (i in 1:nrow(results)) {
data <- simulate_data(results$sample_size[i])
results$estimate[i] <- one_step_estimator_gam(data)
}
ggplot(results, aes(x=estimate, fill=factor(sample_size))) +
geom_density(alpha=0.6) +
geom_vline(xintercept = Psi_P_true, color = "black", linetype = "dashed", size = 1,
show.legend = TRUE, label = "Psi_P_true") +
theme_minimal() +
labs(title="Sampling Distribution of the One-Step Estimator using GAM",
x="Estimate", y="Density", fill="Sample Size")
set.seed(2024)
# Modified function to calculate one-step estimator using GAM
one_step_estimator_gam <- function(data) {
fit_Y <- gam(Y ~ s(L1) + s(L2) +  s(L5) + s(L6) + s(L8) + s(L9) + s(L10), data=data)
fit_A <- gam(A ~ s(L1) + s(L2) +  s(L5) + s(L6) + s(L8) + s(L9) + s(L10), data=data, family=binomial)
m_hat <- predict(fit_Y, newdata=data, type="response")
pi_hat <- predict(fit_A, newdata=data, type="response")
psi_hat_OS <- mean((data$Y - m_hat) * (data$A - pi_hat))
return(psi_hat_OS)
}
# Set simulation parameters
n_sizes <- c(100, 400, 900, 1600, 2500)
n_simulations <- 2
results <- data.frame(sample_size=rep(n_sizes, each=n_simulations), estimate=NA)
# Perform simulations using the GAM-based function
for (i in 1:nrow(results)) {
data <- simulate_data(results$sample_size[i])
results$estimate[i] <- one_step_estimator_gam(data)
}
# Visualize the sampling distributions
ggplot(results, aes(x=estimate, fill=factor(sample_size))) +
geom_density(alpha=0.6) +
geom_vline(xintercept = Psi_P_true, color = "black", linetype = "dashed", size = 1,
show.legend = TRUE, label = "Psi_P_true") +
theme_minimal() +
labs(title="Sampling Distribution of the One-Step Estimator using GAM",
x="Estimate", y="Density", fill="Sample Size")
# Report summary statistics for each sample size
summary_stats_gam <- results %>%
group_by(sample_size) %>%
summarise(
mean_estimate = mean(estimate),
sd = sd(estimate),
var = var(estimate),
bias = mean_estimate - Psi_P_true
)
print(summary_stats_gam)
# Merge GLM and GAM summary statistics
merged_stats <- merge(summary_stats_glm, summary_stats_gam, by="sample_size", suffixes = c("_glm", "_gam"))
# Calculate relative efficiency as the ratio of variances (GLM/GAM)
merged_stats$relative_efficiency <- merged_stats$estimate_glm[,"var"] / merged_stats$estimate_gam[,"var"]
summary_stats_gam
merged_stats <- merge(summary_stats_glm, summary_stats_gam, by="sample_size", suffixes = c("_glm", "_gam"))
merged_stats
merged_stats$relative_efficiency <- merged_stats$estimate_glm[,"var"] / merged_stats$estimate_gam[,"var"]
merged_stats
merged_stats$relative_efficiency <- merged_stats$var_glm / merged_stats$var_gam
merged_stats
relative_efficiency_table <- merged_stats[, c("sample_size", "relative_efficiency")]
relative_efficiency_table
ggplot(results, aes(x=estimate, fill=factor(sample_size))) +
geom_density(alpha=0.6) +
geom_vline(xintercept = Psi_P_true, color = "black", linetype = "dashed", size = 1,
show.legend = TRUE, label = "Psi_P_true") +
theme_minimal() +
labs(title="Sampling Distribution of the One-Step Estimator using GAM",
x="Estimate", y="Density", fill="Sample Size")
rm(list = ls())
nhefs$phi_VTE <- nhefs$phi_cov / plugin_denominator - plugin_numerator * nhefs$phi_var / plugin_denominator^2
# Import data
nhefs <- read.csv("data/nhefs.csv")
# Remove individuals with missing outcome data (n=1566)
nhefs <- nhefs[!is.na(nhefs$wt82_71), ]
# Estimate E(Y|L) and E(A|L) where Y = wt82_71 and A = qsmk
model_Y <- lm(wt82_71 ~ sex + age + I(age^2) + race + factor(education) + smokeintensity + I(smokeintensity^2) + smokeyrs + I(smokeyrs^2) + factor(active) + factor(exercise) + wt71 + I(wt71^2),
data = nhefs)
model_A <- glm(qsmk ~ sex + age + I(age^2) + race + factor(education) + smokeintensity + I(smokeintensity^2) + smokeyrs + I(smokeyrs^2) + factor(active) + factor(exercise) + wt71 + I(wt71^2),
family = binomial, data = nhefs)
# Calculate predictions
nhefs$predicted_Y <- predict(model_Y, newdata = nhefs)
nhefs$predicted_A <- predict(model_A, newdata = nhefs, type = "response")
# Calculate Var(A|L)
nhefs$var_A <- nhefs$predicted_A * (1 - nhefs$predicted_A)
# Calculate Cov(Y,A|L)
nhefs$cov_YA <- with(nhefs, (wt82_71 - predicted_Y) * (qsmk - predicted_A))
# Calculate plug-in estimates
plugin_numerator <- mean(nhefs$cov_YA)
plugin_denominator <- mean(nhefs$var_A)
plugin_VTE <- plugin_numerator / plugin_denominator
plugin_VTE
# Estimate empirical variances and covariances
nhefs$empirical_cov_YA <- with(nhefs, (wt82_71 - predicted_Y) * (qsmk - predicted_A))
nhefs$empirical_var_A <- with(nhefs, (qsmk - predicted_A)^2)
# Estimate influence functions
nhefs$phi_cov <- nhefs$empirical_cov_YA - plugin_numerator
nhefs$phi_var <- nhefs$empirical_var_A - plugin_denominator
# One-step estimator corrections
correction_numerator <- mean(nhefs$phi_cov)
correction_denominator <- mean(nhefs$phi_var)
# Calculate one-step estimator
one_step_VTE <- (plugin_numerator + correction_numerator) / (plugin_denominator + correction_denominator)
one_step_VTE
nhefs$phi_VTE <- nhefs$phi_cov / plugin_denominator - plugin_numerator * nhefs$phi_var / plugin_denominator^2
# Calculate variance of the influence function
var_phi_VTE <- var(nhefs$phi_VTE)
# Standard error of the one-step estimator
se_one_step <- sqrt(var_phi_VTE / nrow(nhefs))
se_one_step
library(boot)
# Define function to calculate VTE
vte_function <- function(data, indices) {
data_boot <- data[indices, ]
model_Y <- lm(wt82_71 ~ sex + age + I(age^2) + race + factor(education) + smokeintensity + I(smokeintensity^2) + smokeyrs + I(smokeyrs^2) + factor(active) + factor(exercise) + wt71 + I(wt71^2),
data = data_boot)
model_A <- glm(qsmk ~ sex + age + I(age^2) + race + factor(education) + smokeintensity + I(smokeintensity^2) + smokeyrs + I(smokeyrs^2) + factor(active) + factor(exercise) + wt71 + I(wt71^2),
family = binomial, data = data_boot)
predicted_Y <- predict(model_Y, newdata = data_boot)
predicted_A <- predict(model_A, newdata = data_boot, type = "response")
var_A <- predicted_A * (1 - predicted_A)
cov_YA <- with(data_boot, (wt82_71 - predicted_Y) * (qsmk - predicted_A))
numerator <- mean(cov_YA)
denominator <- mean(var_A)
return(numerator / denominator)
}
# Bootstrap with 1000 replications
set.seed(2024)
results <- boot(data = nhefs, statistic = vte_function, R = 1000)
# Calculate standard error
bootstrap_se <- sd(results$t)
bootstrap_se
